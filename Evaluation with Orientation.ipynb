{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def orientation_evaluation(gt_pose, pred_rotmat, batch_size, curr_batch_size, step):\n",
    "\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    from scipy.spatial.transform import Rotation as R\n",
    "    \n",
    "    # Orientation evaluation\n",
    "    # Taking as input gt_pose in axis-angle representation and pred_rotmat in rotation matrix representation\n",
    "\n",
    "    gt_rotvec = torch.zeros((curr_batch_size,24,3), dtype=torch.double) # Reshaping the axis-angle (batch, 72) to (batch, 24, 3) for rotation vector compatibility\n",
    "\n",
    "    for i, row in enumerate(gt_pose):\n",
    "        gt_rotvec[i] = torch.reshape(row,(24, -1))\n",
    "\n",
    "    #print(\"gt_rotvec\", gt_rotvec.shape, gt_rotvec)\n",
    "\n",
    "    # Get prediction as rotation vectors\n",
    "\n",
    "    pred_rotvec_arr = np.zeros((curr_batch_size,24,3)) # Has to be a numpy array because it works with Rotation\n",
    "\n",
    "    for i, row in enumerate(pred_rotmat):\n",
    "        r = R.from_dcm(row.cpu()) # create the rotation object from the rotation matrix\n",
    "        pred_rotvec_arr[i] = R.as_rotvec(r) # write it as rotation vectors in pred_rotvec_arr\n",
    "\n",
    "    pred_rotvec = torch.from_numpy(pred_rotvec_arr) # transform it to a tensor\n",
    "\n",
    "    #print(\"pred_rotvec\", pred_rotvec.shape, pred_rotvec)\n",
    "\n",
    "    orientation_error_per_part = np.degrees(torch.sqrt((gt_rotvec - pred_rotvec)**2))\n",
    "    # This gives the error per part\n",
    "\n",
    "    #print(\"error per part\", orientation_error_non_reduced.shape, orientation_error_non_reduced)\n",
    "\n",
    "    orientation_error = np.degrees(torch.sqrt((gt_rotvec - pred_rotvec)**2).sum(dim=-1).mean(dim=-1))\n",
    "    # The reduction above is wrong. For a 90 degree error in one angle, it averages out 3.75 degrees, which\n",
    "    # is 90/24. The correct reduction would be a mean of 1.25 (90/72), because there are 72 angles (3 for each part)\n",
    "    # To remove the root, add [:,1:,:] to gt_euler and pred_euler above\n",
    "\n",
    "    orientation_error_new = np.degrees(torch.sqrt((gt_rotvec - pred_rotvec)**2).mean(dim=[1,2]))\n",
    "    # This reduction is more accurate because it averages the error per part and then the error across parts\n",
    "    # It is equivalent to .mean(dim=-1).mean(dim=-1)\n",
    "\n",
    "    #print(np.size(orientation_error_per_part), orientation_error_per_part)\n",
    "\n",
    "    #print(\"orientation_error\")\n",
    "    #print(orientation_error)\n",
    "    #print()\n",
    "    #print(\"orientation_error_new\")\n",
    "    #print(orientation_error_new)\n",
    "    #print()\n",
    "\n",
    "    return orientation_error_per_part, orientation_error, orientation_error_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script can be used to evaluate a trained model on 3D pose/shape and masks/part segmentation. You first need to download the datasets and preprocess them.\n",
    "Example usage:\n",
    "```\n",
    "python3 eval.py --checkpoint=data/model_checkpoint.pt --dataset=h36m-p1 --log_freq=20\n",
    "```\n",
    "Running the above command will compute the MPJPE and Reconstruction Error on the Human3.6M dataset (Protocol I). The ```--dataset``` option can take different values based on the type of evaluation you want to perform:\n",
    "1. Human3.6M Protocol 1 ```--dataset=h36m-p1```\n",
    "2. Human3.6M Protocol 2 ```--dataset=h36m-p2```\n",
    "3. 3DPW ```--dataset=3dpw```\n",
    "4. LSP ```--dataset=lsp```\n",
    "5. MPI-INF-3DHP ```--dataset=mpi-inf-3dhp```\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "from collections import namedtuple\n",
    "from tqdm import tqdm\n",
    "import torchgeometry as tgm\n",
    "\n",
    "import config\n",
    "import constants\n",
    "from models import hmr, SMPL\n",
    "from datasets import BaseDataset\n",
    "from utils.imutils import uncrop\n",
    "from utils.pose_utils import reconstruction_error\n",
    "from utils.part_utils import PartRenderer\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# Define command-line arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--checkpoint', default=None, help='Path to network checkpoint')\n",
    "parser.add_argument('--dataset', default='h36m-p1', choices=['h36m-p1', 'h36m-p2', 'lsp', '3dpw', 'mpi-inf-3dhp'], help='Choose evaluation dataset')\n",
    "parser.add_argument('--log_freq', default=50, type=int, help='Frequency of printing intermediate results')\n",
    "parser.add_argument('--batch_size', default=32, help='Batch size for testing')\n",
    "parser.add_argument('--shuffle', default=False, action='store_true', help='Shuffle data')\n",
    "parser.add_argument('--num_workers', default=8, type=int, help='Number of processes for data loading')\n",
    "parser.add_argument('--result_file', default=None, help='If set, save detections to a .npz file')\n",
    "\n",
    "def run_evaluation(model, dataset_name, dataset, result_file,\n",
    "                   batch_size=32, img_res=224, \n",
    "                   num_workers=32, shuffle=False, log_freq=50):\n",
    "    \"\"\"Run evaluation on the datasets and metrics we report in the paper. \"\"\"\n",
    "\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # Transfer model to the GPU\n",
    "    model.to(device)\n",
    "\n",
    "    # Load SMPL model\n",
    "    smpl_neutral = SMPL(config.SMPL_MODEL_DIR,\n",
    "                        create_transl=False).to(device)\n",
    "    smpl_male = SMPL(config.SMPL_MODEL_DIR,\n",
    "                     gender='male',\n",
    "                     create_transl=False).to(device)\n",
    "    smpl_female = SMPL(config.SMPL_MODEL_DIR,\n",
    "                       gender='female',\n",
    "                       create_transl=False).to(device)\n",
    "    \n",
    "    renderer = PartRenderer()\n",
    "    \n",
    "    # Regressor for H36m joints\n",
    "    J_regressor = torch.from_numpy(np.load(config.JOINT_REGRESSOR_H36M)).float()\n",
    "    \n",
    "    save_results = result_file is not None\n",
    "    # Disable shuffling if you want to save the results\n",
    "    if save_results:\n",
    "        shuffle=False\n",
    "    # Create dataloader for the dataset\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "    \n",
    "    # Pose metrics\n",
    "    # MPJPE and Reconstruction error for the non-parametric and parametric shapes\n",
    "    mpjpe = np.zeros(len(dataset))\n",
    "    recon_err = np.zeros(len(dataset))\n",
    "    mpjpe_smpl = np.zeros(len(dataset))\n",
    "    recon_err_smpl = np.zeros(len(dataset))\n",
    "    \n",
    "    #Including per joint position error:\n",
    "    pjpe = torch.zeros(len(dataset), 14)\n",
    "    \n",
    "    # Including mean per joint angular error (reduced and per part)\n",
    "    mpjae = np.zeros(len(dataset))\n",
    "    mpjae_per_part = torch.zeros(len(dataset), 24, 3)\n",
    "\n",
    "    # Shape metrics\n",
    "    # Mean per-vertex error\n",
    "    shape_err = np.zeros(len(dataset))\n",
    "    shape_err_smpl = np.zeros(len(dataset))\n",
    "\n",
    "    # Mask and part metrics\n",
    "    # Accuracy\n",
    "    accuracy = 0.\n",
    "    parts_accuracy = 0.\n",
    "    # True positive, false positive and false negative\n",
    "    tp = np.zeros((2,1))\n",
    "    fp = np.zeros((2,1))\n",
    "    fn = np.zeros((2,1))\n",
    "    parts_tp = np.zeros((7,1))\n",
    "    parts_fp = np.zeros((7,1))\n",
    "    parts_fn = np.zeros((7,1))\n",
    "    # Pixel count accumulators\n",
    "    pixel_count = 0\n",
    "    parts_pixel_count = 0\n",
    "\n",
    "    # Store SMPL parameters\n",
    "    smpl_pose = np.zeros((len(dataset), 72))\n",
    "    smpl_betas = np.zeros((len(dataset), 10))\n",
    "    smpl_camera = np.zeros((len(dataset), 3))\n",
    "    pred_joints = np.zeros((len(dataset), 17, 3))\n",
    "\n",
    "    eval_pose = False\n",
    "    eval_masks = False\n",
    "    eval_parts = False\n",
    "    eval_orientation = False # Adding the orientation parameter\n",
    "    # Choose appropriate evaluation for each dataset\n",
    "    if dataset_name == 'h36m-p1' or dataset_name == 'h36m-p2' or dataset_name == 'mpi-inf-3dhp':\n",
    "        eval_pose = True\n",
    "    elif dataset_name == 'lsp':\n",
    "        eval_masks = True\n",
    "        eval_parts = True\n",
    "        annot_path = config.DATASET_FOLDERS['upi-s1h']\n",
    "    elif dataset_name == '3dpw':\n",
    "        eval_orientation = True\n",
    "        eval_pose = True\n",
    "        \n",
    "\n",
    "    joint_mapper_h36m = constants.H36M_TO_J17 if dataset_name == 'mpi-inf-3dhp' else constants.H36M_TO_J14\n",
    "    joint_mapper_gt = constants.J24_TO_J17 if dataset_name == 'mpi-inf-3dhp' else constants.J24_TO_J14\n",
    "    # Iterate over the entire dataset\n",
    "    for step, batch in enumerate(tqdm(data_loader, desc='Eval', total=len(data_loader))):\n",
    "        # Get ground truth annotations from the batch\n",
    "        gt_pose = batch['pose'].to(device)\n",
    "        gt_betas = batch['betas'].to(device)\n",
    "        gt_vertices = smpl_neutral(betas=gt_betas, body_pose=gt_pose[:, 3:], global_orient=gt_pose[:, :3]).vertices\n",
    "        images = batch['img'].to(device)\n",
    "        gender = batch['gender'].to(device)\n",
    "        curr_batch_size = images.shape[0]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred_rotmat, pred_betas, pred_camera = model(images)\n",
    "            pred_output = smpl_neutral(betas=pred_betas, body_pose=pred_rotmat[:,1:], global_orient=pred_rotmat[:,0].unsqueeze(1), pose2rot=False)\n",
    "            pred_vertices = pred_output.vertices\n",
    "\n",
    "        if save_results:\n",
    "            rot_pad = torch.tensor([0,0,1], dtype=torch.float32, device=device).view(1,3,1)\n",
    "            rotmat = torch.cat((pred_rotmat.view(-1, 3, 3), rot_pad.expand(curr_batch_size * 24, -1, -1)), dim=-1)\n",
    "            pred_pose = tgm.rotation_matrix_to_angle_axis(rotmat).contiguous().view(-1, 72)\n",
    "            smpl_pose[step * batch_size:step * batch_size + curr_batch_size, :] = pred_pose.cpu().numpy()\n",
    "            smpl_betas[step * batch_size:step * batch_size + curr_batch_size, :]  = pred_betas.cpu().numpy()\n",
    "            smpl_camera[step * batch_size:step * batch_size + curr_batch_size, :]  = pred_camera.cpu().numpy()\n",
    "        \n",
    "        # Orientation evaluation\n",
    "        orientation_error_per_part, orientation_error, orientation_error_new = \\\n",
    "        orientation_evaluation(gt_pose, pred_rotmat, batch_size, curr_batch_size, step)\n",
    "        \n",
    "        mpjae[step * batch_size:step * batch_size + curr_batch_size] = orientation_error_new\n",
    "        mpjae_per_part[step*batch_size : step*batch_size + curr_batch_size] = orientation_error_per_part\n",
    "            \n",
    "        # 3D pose evaluation\n",
    "        if eval_pose:\n",
    "            # Regressor broadcasting\n",
    "            J_regressor_batch = J_regressor[None, :].expand(pred_vertices.shape[0], -1, -1).to(device)\n",
    "            # Get 14 ground truth joints\n",
    "            if 'h36m' in dataset_name or 'mpi-inf' in dataset_name:\n",
    "                gt_keypoints_3d = batch['pose_3d'].cuda()\n",
    "                gt_keypoints_3d = gt_keypoints_3d[:, joint_mapper_gt, :-1]\n",
    "            # For 3DPW get the 14 common joints from the rendered shape\n",
    "            else:\n",
    "                gt_vertices = smpl_male(global_orient=gt_pose[:,:3], body_pose=gt_pose[:,3:], betas=gt_betas).vertices \n",
    "                gt_vertices_female = smpl_female(global_orient=gt_pose[:,:3], body_pose=gt_pose[:,3:], betas=gt_betas).vertices \n",
    "                gt_vertices[gender==1, :, :] = gt_vertices_female[gender==1, :, :]\n",
    "                gt_keypoints_3d = torch.matmul(J_regressor_batch, gt_vertices) # torch.Size([32, 17, 3]) # This returns 17 joints\n",
    "                gt_pelvis = gt_keypoints_3d[:, [0],:].clone()\n",
    "                gt_keypoints_3d = gt_keypoints_3d[:, joint_mapper_h36m, :] # torch.Size([32, 14, 3]) # But only 14 are used, the joint_mapper is [6, 5, 4, 1, 2, 3, 16, 15, 14, 11, 12, 13, 8, 10]\n",
    "                \n",
    "            # Get 14 predicted joints from the mesh\n",
    "            pred_keypoints_3d = torch.matmul(J_regressor_batch, pred_vertices)\n",
    "            if save_results:\n",
    "                pred_joints[step * batch_size:step * batch_size + curr_batch_size, :, :]  = pred_keypoints_3d.cpu().numpy()\n",
    "            pred_pelvis = pred_keypoints_3d[:, [0],:].clone()\n",
    "            pred_keypoints_3d = pred_keypoints_3d[:, joint_mapper_h36m, :]\n",
    "            pred_keypoints_3d = pred_keypoints_3d - pred_pelvis # [32, 14, 3]\n",
    "            \n",
    "            # Absolute error (MPJPE)\n",
    "            error = torch.sqrt(((pred_keypoints_3d - gt_keypoints_3d) ** 2).sum(dim=-1)).mean(dim=-1).cpu().numpy()\n",
    "            \n",
    "            mpjpe[step * batch_size:step * batch_size + curr_batch_size] = error\n",
    "            \n",
    "            # Per part error\n",
    "            per_part_error = torch.sqrt(((pred_keypoints_3d - gt_keypoints_3d) ** 2).sum(dim=-1)) # Not really necessary to send it to cpu as a np array for now\n",
    "            \n",
    "            pjpe[step * batch_size:step * batch_size + curr_batch_size] = per_part_error*1000 # Converting from meters to milimeters\n",
    "            \n",
    "            # Reconstuction_error\n",
    "            r_error = reconstruction_error(pred_keypoints_3d.cpu().numpy(), gt_keypoints_3d.cpu().numpy(), reduction=None)\n",
    "            recon_err[step * batch_size:step * batch_size + curr_batch_size] = r_error\n",
    "\n",
    "\n",
    "        # If mask or part evaluation, render the mask and part images\n",
    "        if eval_masks or eval_parts:\n",
    "            mask, parts = renderer(pred_vertices, pred_camera)\n",
    "\n",
    "        # Mask evaluation (for LSP)\n",
    "        if eval_masks:\n",
    "            center = batch['center'].cpu().numpy()\n",
    "            scale = batch['scale'].cpu().numpy()\n",
    "            # Dimensions of original image\n",
    "            orig_shape = batch['orig_shape'].cpu().numpy()\n",
    "            for i in range(curr_batch_size):\n",
    "                # After rendering, convert imate back to original resolution\n",
    "                pred_mask = uncrop(mask[i].cpu().numpy(), center[i], scale[i], orig_shape[i]) > 0\n",
    "                # Load gt mask\n",
    "                gt_mask = cv2.imread(os.path.join(annot_path, batch['maskname'][i]), 0) > 0\n",
    "                # Evaluation consistent with the original UP-3D code\n",
    "                accuracy += (gt_mask == pred_mask).sum()\n",
    "                pixel_count += np.prod(np.array(gt_mask.shape))\n",
    "                for c in range(2):\n",
    "                    cgt = gt_mask == c\n",
    "                    cpred = pred_mask == c\n",
    "                    tp[c] += (cgt & cpred).sum()\n",
    "                    fp[c] +=  (~cgt & cpred).sum()\n",
    "                    fn[c] +=  (cgt & ~cpred).sum()\n",
    "                f1 = 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "        # Part evaluation (for LSP)\n",
    "        if eval_parts:\n",
    "            center = batch['center'].cpu().numpy()\n",
    "            scale = batch['scale'].cpu().numpy()\n",
    "            orig_shape = batch['orig_shape'].cpu().numpy()\n",
    "            for i in range(curr_batch_size):\n",
    "                pred_parts = uncrop(parts[i].cpu().numpy().astype(np.uint8), center[i], scale[i], orig_shape[i])\n",
    "                # Load gt part segmentation\n",
    "                gt_parts = cv2.imread(os.path.join(annot_path, batch['partname'][i]), 0)\n",
    "                # Evaluation consistent with the original UP-3D code\n",
    "                # 6 parts + background\n",
    "                for c in range(7):\n",
    "                   cgt = gt_parts == c\n",
    "                   cpred = pred_parts == c\n",
    "                   cpred[gt_parts == 255] = 0\n",
    "                   parts_tp[c] += (cgt & cpred).sum()\n",
    "                   parts_fp[c] +=  (~cgt & cpred).sum()\n",
    "                   parts_fn[c] +=  (cgt & ~cpred).sum()\n",
    "                gt_parts[gt_parts == 255] = 0\n",
    "                pred_parts[pred_parts == 255] = 0\n",
    "                parts_f1 = 2 * parts_tp / (2 * parts_tp + parts_fp + parts_fn)\n",
    "                parts_accuracy += (gt_parts == pred_parts).sum()\n",
    "                parts_pixel_count += np.prod(np.array(gt_parts.shape))\n",
    "\n",
    "        # Print intermediate results during evaluation\n",
    "        if step % log_freq == log_freq - 1:\n",
    "            if eval_pose:\n",
    "                print('MPJPE: ' + str(1000 * mpjpe[:step * batch_size].mean()))\n",
    "                print('Reconstruction Error: ' + str(1000 * recon_err[:step * batch_size].mean()))\n",
    "                print()\n",
    "            if eval_masks:\n",
    "                print('Accuracy: ', accuracy / pixel_count)\n",
    "                print('F1: ', f1.mean())\n",
    "                print()\n",
    "            if eval_parts:\n",
    "                print('Parts Accuracy: ', parts_accuracy / parts_pixel_count)\n",
    "                print('Parts F1 (BG): ', parts_f1[[0,1,2,3,4,5,6]].mean())\n",
    "                print()\n",
    "            if eval_orientation:\n",
    "                print('Orientation error: ' + str(mpjae[:step * batch_size].mean()))\n",
    "\n",
    "    # Save reconstructions to a file for further processing\n",
    "    if save_results:\n",
    "        np.savez(result_file, pred_joints=pred_joints, pose=smpl_pose, betas=smpl_betas, camera=smpl_camera)\n",
    "    # Print final results during evaluation\n",
    "    print('*** Final Results ***')\n",
    "    print()\n",
    "    if eval_pose:\n",
    "        print('MPJPE: ' + str(1000 * mpjpe.mean()))\n",
    "        print('Reconstruction Error: ' + str(1000 * recon_err.mean()))\n",
    "        print()\n",
    "        #torch.save(pjpe, 'pjpe.pt') # Uncomment to save the raw data to a file\n",
    "    if eval_masks:\n",
    "        print('Accuracy: ', accuracy / pixel_count)\n",
    "        print('F1: ', f1.mean())\n",
    "        print()\n",
    "    if eval_parts:\n",
    "        print('Parts Accuracy: ', parts_accuracy / parts_pixel_count)\n",
    "        print('Parts F1 (BG): ', parts_f1[[0,1,2,3,4,5,6]].mean())\n",
    "        print()\n",
    "    if eval_orientation:\n",
    "        print('Orientation Error: ' + str(mpjae.mean()))\n",
    "        #torch.save(mpjae_per_part, 'mpjae_per_part.pt') # Uncomment to save the raw data to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:   2%|▏         | 20/1110 [00:53<24:04,  1.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 258.302748472871\n",
      "Reconstruction Error: 41.73969474351524\n",
      "\n",
      "Orientation error: 8.301217391926139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:   4%|▎         | 40/1110 [01:04<13:32,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 255.45146458376294\n",
      "Reconstruction Error: 45.72069015538988\n",
      "\n",
      "Orientation error: 8.917448099172002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:   5%|▌         | 60/1110 [01:23<08:25,  2.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 258.37807915315534\n",
      "Reconstruction Error: 51.43223865395728\n",
      "\n",
      "Orientation error: 9.283912416846842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:   7%|▋         | 80/1110 [01:38<24:59,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 254.0992265508239\n",
      "Reconstruction Error: 52.19270242820199\n",
      "\n",
      "Orientation error: 9.357562113788697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:   9%|▉         | 100/1110 [01:53<07:56,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 254.98455132574145\n",
      "Reconstruction Error: 52.069855499965605\n",
      "\n",
      "Orientation error: 9.492716857255799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  11%|█         | 120/1110 [02:13<12:40,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 254.90549700960767\n",
      "Reconstruction Error: 52.26824524031733\n",
      "\n",
      "Orientation error: 9.43975521834012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  13%|█▎        | 140/1110 [02:34<10:27,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 256.5847681299281\n",
      "Reconstruction Error: 54.08132513993414\n",
      "\n",
      "Orientation error: 9.605082343641998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  14%|█▍        | 160/1110 [02:57<16:34,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 259.7108210595149\n",
      "Reconstruction Error: 56.63475359653843\n",
      "\n",
      "Orientation error: 9.98932664327239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  16%|█▌        | 180/1110 [03:08<07:09,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 261.3269016510864\n",
      "Reconstruction Error: 58.154168628174396\n",
      "\n",
      "Orientation error: 10.074377547260031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  18%|█▊        | 200/1110 [03:25<17:41,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 264.12795261297396\n",
      "Reconstruction Error: 60.300487976102396\n",
      "\n",
      "Orientation error: 10.417564531309836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  20%|█▉        | 220/1110 [03:36<10:15,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 264.5456417374415\n",
      "Reconstruction Error: 60.335253372779924\n",
      "\n",
      "Orientation error: 10.298260807738503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  22%|██▏       | 240/1110 [03:48<16:21,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 264.23713025757775\n",
      "Reconstruction Error: 59.34126643613994\n",
      "\n",
      "Orientation error: 10.098604911945815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  23%|██▎       | 260/1110 [03:58<06:45,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.29758939390075\n",
      "Reconstruction Error: 59.57728419156249\n",
      "\n",
      "Orientation error: 9.885730506637461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  25%|██▌       | 280/1110 [04:08<06:22,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.608465105402\n",
      "Reconstruction Error: 59.86795281343776\n",
      "\n",
      "Orientation error: 9.770727506474236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  27%|██▋       | 300/1110 [04:17<06:28,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.7951340145466\n",
      "Reconstruction Error: 59.400126206015784\n",
      "\n",
      "Orientation error: 9.699317643240029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  29%|██▉       | 320/1110 [04:27<05:36,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.5884116282073\n",
      "Reconstruction Error: 58.77969355952304\n",
      "\n",
      "Orientation error: 9.638661989302124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  31%|███       | 340/1110 [04:43<05:37,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.23026505359906\n",
      "Reconstruction Error: 58.429864136664236\n",
      "\n",
      "Orientation error: 9.644130566835804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  32%|███▏      | 360/1110 [04:52<07:19,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.49361317406584\n",
      "Reconstruction Error: 58.745721748590334\n",
      "\n",
      "Orientation error: 9.702722487781003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  34%|███▍      | 380/1110 [04:59<04:47,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.2016415948879\n",
      "Reconstruction Error: 58.06407759977888\n",
      "\n",
      "Orientation error: 9.666777709845965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  36%|███▌      | 400/1110 [05:09<04:46,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.07458764701187\n",
      "Reconstruction Error: 58.019773218545005\n",
      "\n",
      "Orientation error: 9.65897574341051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  38%|███▊      | 420/1110 [05:19<05:39,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.32001874901727\n",
      "Reconstruction Error: 58.609448586421664\n",
      "\n",
      "Orientation error: 9.630202759782692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  40%|███▉      | 440/1110 [05:29<07:54,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.6004983228812\n",
      "Reconstruction Error: 58.6497319655669\n",
      "\n",
      "Orientation error: 9.65047314931424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  41%|████▏     | 460/1110 [05:39<04:54,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.52462300002446\n",
      "Reconstruction Error: 58.50512626662562\n",
      "\n",
      "Orientation error: 9.62443830232045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  43%|████▎     | 480/1110 [05:51<06:12,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.25962898384057\n",
      "Reconstruction Error: 58.182424668802064\n",
      "\n",
      "Orientation error: 9.600506167123314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  45%|████▌     | 500/1110 [06:00<04:08,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.14635409544667\n",
      "Reconstruction Error: 58.448527782958536\n",
      "\n",
      "Orientation error: 9.630988569460293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  47%|████▋     | 520/1110 [06:16<07:31,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.34653000186177\n",
      "Reconstruction Error: 58.31344849012814\n",
      "\n",
      "Orientation error: 9.604472781011264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  49%|████▊     | 540/1110 [06:27<03:30,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.25596146152833\n",
      "Reconstruction Error: 58.254984513068564\n",
      "\n",
      "Orientation error: 9.580903662937596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  50%|█████     | 560/1110 [06:40<05:16,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.70334216837034\n",
      "Reconstruction Error: 58.56073017970181\n",
      "\n",
      "Orientation error: 9.60804681764662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  52%|█████▏    | 580/1110 [06:50<04:49,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.3503608470123\n",
      "Reconstruction Error: 58.600691264770305\n",
      "\n",
      "Orientation error: 9.62137952931423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  54%|█████▍    | 600/1110 [07:08<09:01,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 264.49780940592836\n",
      "Reconstruction Error: 58.671167013542465\n",
      "\n",
      "Orientation error: 9.660806977401156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  56%|█████▌    | 620/1110 [07:16<03:37,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.4157053823666\n",
      "Reconstruction Error: 59.056694609295846\n",
      "\n",
      "Orientation error: 9.712031446028323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  58%|█████▊    | 640/1110 [07:26<03:03,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.30999287668504\n",
      "Reconstruction Error: 58.97930473984104\n",
      "\n",
      "Orientation error: 9.688309270678893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  59%|█████▉    | 660/1110 [07:38<10:48,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.1495661209189\n",
      "Reconstruction Error: 58.879174257639924\n",
      "\n",
      "Orientation error: 9.706401420119855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  61%|██████▏   | 680/1110 [07:44<02:52,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.274612540969\n",
      "Reconstruction Error: 58.78070097569917\n",
      "\n",
      "Orientation error: 9.719306826425552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  63%|██████▎   | 700/1110 [07:52<02:16,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.3549567387254\n",
      "Reconstruction Error: 58.85737522137825\n",
      "\n",
      "Orientation error: 9.692356570138148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  65%|██████▍   | 720/1110 [08:00<02:56,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.67517380166663\n",
      "Reconstruction Error: 59.00512578933123\n",
      "\n",
      "Orientation error: 9.6439248069934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  67%|██████▋   | 740/1110 [08:13<03:03,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.6918140449618\n",
      "Reconstruction Error: 58.89322938090657\n",
      "\n",
      "Orientation error: 9.620443120744646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  68%|██████▊   | 760/1110 [08:27<04:28,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.5745847322469\n",
      "Reconstruction Error: 58.57721782387302\n",
      "\n",
      "Orientation error: 9.588335140923272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  70%|███████   | 780/1110 [08:49<03:20,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.4005123131379\n",
      "Reconstruction Error: 58.39607550954477\n",
      "\n",
      "Orientation error: 9.550964598636195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  72%|███████▏  | 800/1110 [09:00<02:46,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.1710090593427\n",
      "Reconstruction Error: 57.99854259979672\n",
      "\n",
      "Orientation error: 9.503799512276396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  74%|███████▍  | 820/1110 [09:14<01:16,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 264.9366574950962\n",
      "Reconstruction Error: 57.79588696977831\n",
      "\n",
      "Orientation error: 9.477754139324057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  76%|███████▌  | 840/1110 [09:28<03:35,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 264.93755925593274\n",
      "Reconstruction Error: 57.86474810883234\n",
      "\n",
      "Orientation error: 9.458699660016924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  77%|███████▋  | 860/1110 [09:37<01:46,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 264.87761693795204\n",
      "Reconstruction Error: 57.93397206074761\n",
      "\n",
      "Orientation error: 9.442182616950156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  79%|███████▉  | 880/1110 [09:47<01:44,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.0106905120403\n",
      "Reconstruction Error: 57.8205072296761\n",
      "\n",
      "Orientation error: 9.47823908191114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  81%|████████  | 900/1110 [09:59<05:29,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.33248515652537\n",
      "Reconstruction Error: 58.48229867663883\n",
      "\n",
      "Orientation error: 9.488770803599863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  83%|████████▎ | 920/1110 [10:09<01:31,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.73693249131406\n",
      "Reconstruction Error: 58.6964388434842\n",
      "\n",
      "Orientation error: 9.525968189919906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  85%|████████▍ | 940/1110 [10:21<01:07,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.9381592821794\n",
      "Reconstruction Error: 59.01189623298907\n",
      "\n",
      "Orientation error: 9.56078473060671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  86%|████████▋ | 960/1110 [10:31<01:10,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 266.0863194303884\n",
      "Reconstruction Error: 59.126139828161755\n",
      "\n",
      "Orientation error: 9.60315614591921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  88%|████████▊ | 980/1110 [10:41<00:55,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 265.6660221447641\n",
      "Reconstruction Error: 59.10551878527345\n",
      "\n",
      "Orientation error: 9.593283433895452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  90%|█████████ | 1000/1110 [10:50<00:54,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 264.8650640351428\n",
      "Reconstruction Error: 58.9993816286044\n",
      "\n",
      "Orientation error: 9.5840790235374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  92%|█████████▏| 1020/1110 [10:57<00:36,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 264.6728005608447\n",
      "Reconstruction Error: 58.967273942433884\n",
      "\n",
      "Orientation error: 9.566197215521473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  94%|█████████▎| 1040/1110 [11:04<00:27,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 264.0446424659044\n",
      "Reconstruction Error: 58.8947771684826\n",
      "\n",
      "Orientation error: 9.54798952087937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  96%|█████████▌| 1061/1110 [11:10<00:10,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 264.17789981956395\n",
      "Reconstruction Error: 59.077177788766335\n",
      "\n",
      "Orientation error: 9.545936897417256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  97%|█████████▋| 1081/1110 [11:13<00:03,  9.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 263.85505667406863\n",
      "Reconstruction Error: 59.155131115140506\n",
      "\n",
      "Orientation error: 9.5267607877964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval:  99%|█████████▉| 1101/1110 [11:15<00:00,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPJPE: 264.2032136099143\n",
      "Reconstruction Error: 59.31143591334464\n",
      "\n",
      "Orientation error: 9.518863738219308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: 100%|██████████| 1110/1110 [11:17<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Final Results ***\n",
      "\n",
      "MPJPE: 264.2195101033864\n",
      "Reconstruction Error: 59.28574676292263\n",
      "\n",
      "Orientation Error: 9.5149063225102\n",
      "Orientation Error per part:  tensor([[[3.4467e+02, 1.3718e+00, 1.4633e+00],\n",
      "         [1.1698e+01, 5.1830e+00, 1.1266e+00],\n",
      "         [1.6275e+01, 5.3367e-01, 3.6228e+00],\n",
      "         ...,\n",
      "         [1.1765e+01, 2.5596e+00, 5.4265e+00],\n",
      "         [2.4144e+00, 3.2284e+00, 2.4397e+00],\n",
      "         [1.5845e-02, 1.9711e+00, 1.9843e+00]],\n",
      "\n",
      "        [[3.4505e+02, 1.3102e+00, 2.2830e+00],\n",
      "         [1.2002e+01, 4.3776e+00, 8.9079e-01],\n",
      "         [1.6749e+01, 1.0212e+00, 3.5849e+00],\n",
      "         ...,\n",
      "         [1.2371e+01, 2.3686e+00, 4.4567e+00],\n",
      "         [2.3773e+00, 3.2820e+00, 2.4814e+00],\n",
      "         [7.9473e-02, 2.0159e+00, 2.0162e+00]],\n",
      "\n",
      "        [[3.4473e+02, 1.5390e+00, 6.8220e-01],\n",
      "         [1.2073e+01, 4.2944e+00, 7.8759e-01],\n",
      "         [1.6626e+01, 8.6043e-01, 3.1790e+00],\n",
      "         ...,\n",
      "         [1.2720e+01, 2.0895e+00, 4.3858e+00],\n",
      "         [2.3054e+00, 3.2469e+00, 2.3463e+00],\n",
      "         [5.4784e-02, 2.0718e+00, 1.8829e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.7220e-01, 7.2250e-01, 8.8003e-01],\n",
      "         [2.7680e+01, 8.2778e+00, 2.6606e-01],\n",
      "         [2.2009e+01, 2.4660e+00, 2.8487e+00],\n",
      "         ...,\n",
      "         [1.1571e+01, 1.2562e+01, 2.7599e+00],\n",
      "         [2.6513e+00, 3.2649e+00, 2.7440e+00],\n",
      "         [1.7223e+00, 1.8142e+00, 3.3679e+00]],\n",
      "\n",
      "        [[7.2369e-01, 6.6008e-01, 1.1647e+00],\n",
      "         [2.7802e+01, 8.0847e+00, 1.0996e-01],\n",
      "         [2.2042e+01, 2.6435e+00, 2.6267e+00],\n",
      "         ...,\n",
      "         [1.1352e+01, 1.2526e+01, 2.6663e+00],\n",
      "         [2.6411e+00, 3.2078e+00, 2.6607e+00],\n",
      "         [1.6383e+00, 1.8003e+00, 3.3068e+00]],\n",
      "\n",
      "        [[8.8051e-01, 5.2048e-01, 2.4036e+00],\n",
      "         [2.7881e+01, 7.7689e+00, 8.2888e-02],\n",
      "         [2.2323e+01, 2.5508e+00, 2.5387e+00],\n",
      "         ...,\n",
      "         [1.1442e+01, 1.2153e+01, 2.5162e+00],\n",
      "         [2.5933e+00, 3.1751e+00, 2.6084e+00],\n",
      "         [1.6773e+00, 1.7991e+00, 3.2753e+00]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # python3 eval.py --checkpoint=data/model_checkpoint.pt --dataset=h36m-p1 --log_freq=20 // example code\n",
    "    args = parser.parse_args(['--checkpoint=data/model_checkpoint.pt','--dataset=3dpw', '--log_freq=20'])\n",
    "    # Here we inserted our own arguments list\n",
    "    \n",
    "    model = hmr(config.SMPL_MEAN_PARAMS)\n",
    "    checkpoint = torch.load(args.checkpoint)\n",
    "    model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    # Setup evaluation dataset\n",
    "    dataset = BaseDataset(None, args.dataset, is_train=False)\n",
    "    # Run evaluation\n",
    "    run_evaluation(model, args.dataset, dataset, args.result_file,\n",
    "                   batch_size=args.batch_size,\n",
    "                   shuffle=args.shuffle,\n",
    "                   log_freq=args.log_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
