{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TotalCapture pre-processing (to pair it with AMASS SMPL ground truth)\n",
    "\n",
    "Start by getting a list of the TotalCapture recordings that have a .npz linked to it, and that match in length (e.g. some .npz's have less frames than the videos, and are thus disconsidered)\n",
    "\n",
    "Then, with this list saved in a dictionary placed at the working directory,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be ran at the directory holding both AMASS and TotalCapture\n",
    "# (e.g. place AMASS inside the data folder in TotalCaptureToolbox)\n",
    "# root\n",
    "#  data\n",
    "#   AMASS\n",
    "#   images\n",
    "\n",
    "# Create a dictionary containing the name of the action in TotalCapture-Toolbox and AMASS notation,\n",
    "# and whether there is a .npz file for it and if it's a match (frames to number of poses)\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "subject_map = {1: 's1', 2: 's2', 3: 's3', 4: 's4', 5: 's5'}\n",
    "action_map = {1: 'rom', 2: 'walking', 3: 'acting', 4: 'running', 5: 'freestyle'}\n",
    "\n",
    "def to_npz_name(total_capture_path):\n",
    "    _, short_path = os.path.split(total_capture_path) # Throw out all path but 's_xx_act_xx_subact_xx_ca_xx'\n",
    "    npz_style_name = os.path.join(subject_map[int(short_path[3])], action_map[int(short_path[10])] + short_path[-7] + '_poses.npz')\n",
    "    return npz_style_name\n",
    "\n",
    "npz_path = 'data/AMASS/'\n",
    "npz_paths = glob.glob(npz_path+'*/*') # Gets all .npz's names from amass\n",
    "\n",
    "npz_short_paths = []\n",
    "\n",
    "for i, path in enumerate(npz_paths):\n",
    "    head, action = os.path.split(npz_paths[i])\n",
    "    _, subject = os.path.split(head)\n",
    "    short_npz = os.path.join(subject, action)\n",
    "    npz_short_paths.append(short_npz)\n",
    "    \n",
    "\n",
    "image_path = 'data/images/'\n",
    "img_paths = glob.glob(image_path+'*') # Gets all actions, subactions and camera folder names\n",
    "img_paths = [path for path in img_paths if os.path.isdir(path)]\n",
    "\n",
    "short_paths = []\n",
    "frames_in_path = []\n",
    "npz_style_names = []\n",
    "has_npzs = []\n",
    "matches_frames = []\n",
    "n_poses = []\n",
    "\n",
    "action_camera_dict = {}\n",
    "\n",
    "for i, path in enumerate(img_paths):\n",
    "    print('Found path:', path)\n",
    "    n_frames = (len(os.listdir(path))) # Counts how many images are inside the folder\n",
    "    _, short_path = os.path.split(img_paths[i]) # Throw out all path but 's_xx_act_xx_subact_xx_ca_xx'\n",
    "    npz_style_name = to_npz_name(path)\n",
    "    has_npz = npz_style_name in npz_short_paths\n",
    "\n",
    "    match_frames = False\n",
    "    n_pose = None\n",
    "    \n",
    "    if has_npz:\n",
    "        arr = np.load(os.path.join(npz_path, npz_style_name))\n",
    "        n_pose = arr['poses'].shape[0]\n",
    "        match_frames = (n_pose == n_frames)\n",
    "    \n",
    "    action_camera_dict[short_path] = {'n_frames': n_frames,\n",
    "                                   'has_npz': has_npz,\n",
    "                                   'npz_style_name': npz_style_name,\n",
    "                                   'n_poses': n_pose,\n",
    "                                   'is_a_match': match_frames}\n",
    "\n",
    "# Uncomment to store .pkl\n",
    "# The created .pkl should have 296 entries with 'has_npz' = True, since that's 37 AMASS files * 8 cameras.\n",
    "\n",
    "f = open('action_camera_dict.pkl', 'wb')\n",
    "pickle.dump(action_camera_dict, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of pre-processing code\n",
    "\n",
    "After getting a dictionary containing the actions in Total capture with the code above, we extract the image name, center and scale from the annotations in the dictionary that have 'is_a_match' set to True. This means only actions & cameras that exactly match the number of frames to the corresponding AMASS .npz are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMASS_TOTAL_CAPTURE_ROOT = 'data/AMASS/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_npz_name(total_capture_img_path):\n",
    "    # Returns the frame number of the image and the npz style name of the action\n",
    "    \n",
    "    import os\n",
    "    \n",
    "    subject_map = {1: 's1', 2: 's2', 3: 's3', 4: 's4', 5: 's5'}\n",
    "    action_map = {1: 'rom', 2: 'walking', 3: 'acting', 4: 'running', 5: 'freestyle'}\n",
    "    \n",
    "    folder, file = os.path.split(total_capture_img_path) # Separate image and folder\n",
    "    _, short_path = os.path.split(folder) # Throw out everything from the folder except 's_xx_act_xx_subact_xx_ca_xx'\n",
    "    \n",
    "    npz_style_name = os.path.join(subject_map[int(short_path[3])], action_map[int(short_path[10])] + short_path[-7] + '_poses.npz')\n",
    "    frame = file[:-4]\n",
    "    frame = int(frame)\n",
    "    \n",
    "    return npz_style_name, frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_from_current_npz(total_capture_img_path, npz_file):\n",
    "    return img_to_npz_name(total_capture_img_path)[0] == short_npz_name(npz_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'action_camera_dict.pkl'\n",
    "\n",
    "with open(filename, 'rb') as f:\n",
    "    action_camera_dict = pickle.load(f, encoding='latin1')\n",
    "\n",
    "def is_valid_image(image):\n",
    "    folder, _ = os.path.split(image)\n",
    "    if action_camera_dict[folder]['is_a_match']:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def short_npz_name(file_name):\n",
    "    short_name = file_name[len(AMASS_TOTAL_CAPTURE_ROOT):]\n",
    "    return short_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the relevant .pkl with annotations from TotalCapture (Either train or validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#filename = 'totalcapture_train.pkl'\n",
    "filename = 'totalcapture_validation.pkl'\n",
    "\n",
    "with open(filename, 'rb') as f:\n",
    "    pkl_data = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE = 0.1 # Set the probability we will use an image (0.1 to downsample ten times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/AMASS/s5/rom3_poses.npz', 'data/AMASS/s5/walking2_poses.npz', 'data/AMASS/s5/freestyle1_poses.npz', 'data/AMASS/s5/freestyle3_poses.npz', 'data/AMASS/s2/rom3_poses.npz', 'data/AMASS/s2/walking3_poses.npz', 'data/AMASS/s2/walking2_poses.npz', 'data/AMASS/s2/walking1_poses.npz', 'data/AMASS/s2/rom2_poses.npz', 'data/AMASS/s2/rom1_poses.npz', 'data/AMASS/s2/acting1_poses.npz', 'data/AMASS/s2/acting3_poses.npz', 'data/AMASS/s2/acting2_poses.npz', 'data/AMASS/s2/freestyle2_poses.npz', 'data/AMASS/s4/rom3_poses.npz', 'data/AMASS/s4/walking2_poses.npz', 'data/AMASS/s4/freestyle1_poses.npz', 'data/AMASS/s4/freestyle3_poses.npz', 'data/AMASS/s1/rom3_poses.npz', 'data/AMASS/s1/walking3_poses.npz', 'data/AMASS/s1/walking2_poses.npz', 'data/AMASS/s1/walking1_poses.npz', 'data/AMASS/s1/rom2_poses.npz', 'data/AMASS/s1/freestyle1_poses.npz', 'data/AMASS/s1/rom1_poses.npz', 'data/AMASS/s1/acting1_poses.npz', 'data/AMASS/s1/acting3_poses.npz', 'data/AMASS/s1/freestyle3_poses.npz', 'data/AMASS/s1/acting2_poses.npz', 'data/AMASS/s1/freestyle2_poses.npz', 'data/AMASS/s3/rom3_poses.npz', 'data/AMASS/s3/walking3_poses.npz', 'data/AMASS/s3/walking2_poses.npz', 'data/AMASS/s3/walking1_poses.npz', 'data/AMASS/s3/rom2_poses.npz', 'data/AMASS/s3/rom1_poses.npz', 'data/AMASS/s3/acting2_poses.npz']\n",
      "processed data/AMASS/s5/rom3_poses.npz\n",
      "processing  data/AMASS/s5/walking2_poses.npz 0 total frames\n",
      "processing  data/AMASS/s5/walking2_poses.npz 1000 total frames\n",
      "processing  data/AMASS/s5/walking2_poses.npz 2000 total frames\n",
      "processing  data/AMASS/s5/walking2_poses.npz 3000 total frames\n",
      "processed data/AMASS/s5/walking2_poses.npz\n",
      "processed data/AMASS/s5/freestyle1_poses.npz\n",
      "processed data/AMASS/s5/freestyle3_poses.npz\n",
      "processed data/AMASS/s2/rom3_poses.npz\n",
      "processed data/AMASS/s2/walking3_poses.npz\n",
      "processing  data/AMASS/s2/walking2_poses.npz 4000 total frames\n",
      "processing  data/AMASS/s2/walking2_poses.npz 5000 total frames\n",
      "processed data/AMASS/s2/walking2_poses.npz\n",
      "processed data/AMASS/s2/walking1_poses.npz\n",
      "processed data/AMASS/s2/rom2_poses.npz\n",
      "processed data/AMASS/s2/rom1_poses.npz\n",
      "processed data/AMASS/s2/acting1_poses.npz\n",
      "processed data/AMASS/s2/acting3_poses.npz\n",
      "processed data/AMASS/s2/acting2_poses.npz\n",
      "processed data/AMASS/s2/freestyle2_poses.npz\n",
      "processed data/AMASS/s4/rom3_poses.npz\n",
      "processed data/AMASS/s4/walking2_poses.npz\n",
      "processed data/AMASS/s4/freestyle1_poses.npz\n",
      "processing  data/AMASS/s4/freestyle3_poses.npz 6000 total frames\n",
      "processing  data/AMASS/s4/freestyle3_poses.npz 7000 total frames\n",
      "processing  data/AMASS/s4/freestyle3_poses.npz 8000 total frames\n",
      "processed data/AMASS/s4/freestyle3_poses.npz\n",
      "processed data/AMASS/s1/rom3_poses.npz\n",
      "processed data/AMASS/s1/walking3_poses.npz\n",
      "processed data/AMASS/s1/walking2_poses.npz\n",
      "processed data/AMASS/s1/walking1_poses.npz\n",
      "processed data/AMASS/s1/rom2_poses.npz\n",
      "processed data/AMASS/s1/freestyle1_poses.npz\n",
      "processed data/AMASS/s1/rom1_poses.npz\n",
      "processed data/AMASS/s1/acting1_poses.npz\n",
      "processed data/AMASS/s1/acting3_poses.npz\n",
      "processing  data/AMASS/s1/freestyle3_poses.npz 9000 total frames\n",
      "processed data/AMASS/s1/freestyle3_poses.npz\n",
      "processed data/AMASS/s1/acting2_poses.npz\n",
      "processed data/AMASS/s1/freestyle2_poses.npz\n",
      "processed data/AMASS/s3/rom3_poses.npz\n",
      "processed data/AMASS/s3/walking3_poses.npz\n",
      "processed data/AMASS/s3/walking2_poses.npz\n",
      "processed data/AMASS/s3/walking1_poses.npz\n",
      "processed data/AMASS/s3/rom2_poses.npz\n",
      "processed data/AMASS/s3/rom1_poses.npz\n",
      "processed data/AMASS/s3/acting2_poses.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "\n",
    "imgnames_ = []\n",
    "centers_ = []\n",
    "scales_ = []\n",
    "\n",
    "poses_ = []\n",
    "shapes_ = []\n",
    "genders_ = []\n",
    "\n",
    "npz_files = glob.glob(AMASS_TOTAL_CAPTURE_ROOT+'*/*')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "i=0\n",
    "for file in npz_files:\n",
    "    with np.load(file, mmap_mode = 'r') as f:\n",
    "        for d in pkl_data:\n",
    "            if is_valid_image(d['image']):\n",
    "                if np.random.random() < SAMPLING_RATE:\n",
    "                    if img_to_npz_name(d['image'])[0] == short_npz_name(file):\n",
    "\n",
    "                        imgname = d['image']\n",
    "\n",
    "                        npz_style_name, frame = img_to_npz_name(imgname)\n",
    "\n",
    "                        center = d['center']\n",
    "                        scale = max(d['scale'])\n",
    "\n",
    "                        pose = np.copy(f['poses'][frame][:72]) # Loads the first 72 of thee 156-size pose from AMASS (because it includes hand pose)\n",
    "                        shape = np.copy(f['betas'][:10]) # Loads the first 10 of the 16 betas\n",
    "                        gender = (str(f['gender'])[0]) # Loads the first letter of the gender string\n",
    "\n",
    "                        imgnames_.append(imgname)\n",
    "                        centers_.append(center)\n",
    "                        scales_.append(scale)\n",
    "                        poses_.append(pose)\n",
    "                        shapes_.append(shape)\n",
    "                        genders_.append(gender)\n",
    "\n",
    "\n",
    "                        if (i % 1000==0):\n",
    "                            print('processing ', file, i, 'total frames')\n",
    "                        i+=1\n",
    "\n",
    "        print('processed', file)\n",
    "\n",
    "out_path = '.'\n",
    "out_file = os.path.join(out_path, filename[:-4] + str(SAMPLING_RATE) + '.npz')\n",
    "np.savez(out_file, imgname=imgnames_,\n",
    "                       center=centers_,\n",
    "                       scale=scales_,\n",
    "                       pose=poses_,\n",
    "                       shape=shapes_,\n",
    "                       gender=genders_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(npz['imgname'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save imgnames to a .txt for batch copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('copy_list_subsampled.txt', npz['imgname'], fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
